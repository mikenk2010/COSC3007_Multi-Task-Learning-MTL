{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1763b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.12.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa02bc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X shape: (3000, 32, 32)\n",
      "Targets y shape: (3000, 3)\n",
      "Target A (10-class): range [0, 9]\n",
      "Target B (32-class): 32 classes\n",
      "Target C (Regression): range [0.0003, 0.9996]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = np.load('dataset_dev_3000.npz')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "print(f\"Input X shape: {X.shape}\")\n",
    "print(f\"Targets y shape: {y.shape}\")\n",
    "print(f\"Target A (10-class): range [{y[:, 0].min():.0f}, {y[:, 0].max():.0f}]\")\n",
    "print(f\"Target B (32-class): {len(np.unique(y[:, 1]))} classes\")\n",
    "print(f\"Target C (Regression): range [{y[:, 2].min():.4f}, {y[:, 2].max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bffb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourier Transform layer defined\n"
     ]
    }
   ],
   "source": [
    "def apply_2d_fft(images):\n",
    "    \"\"\"Apply simple 2D FFT to batch of images - returns magnitude and phase\"\"\"\n",
    "    # Input shape: (batch, 32, 32, 1) or (batch, 32, 32)\n",
    "    # Ensure we have the right shape\n",
    "    if images.ndim == 4:\n",
    "        images_squeezed = images[:, :, :, 0]  # (batch, 32, 32)\n",
    "    else:\n",
    "        images_squeezed = images\n",
    "    \n",
    "    # Apply 2D FFT using numpy\n",
    "    fft_result = np.fft.fft2(images_squeezed)\n",
    "    \n",
    "    # Shift zero frequency to center\n",
    "    fft_shifted = np.fft.fftshift(fft_result)\n",
    "    \n",
    "    # Get magnitude\n",
    "    magnitude = np.abs(fft_shifted)\n",
    "    \n",
    "    # Get phase\n",
    "    phase = np.angle(fft_shifted)\n",
    "    \n",
    "    # Stack magnitude and phase as 2 channels: (batch, 32, 32, 2)\n",
    "    output = np.stack([magnitude, phase], axis=-1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "class FourierTransformLayer(layers.Layer):\n",
    "    \"\"\"Custom layer to apply 2D Fourier Transform\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Convert to numpy, apply FFT, convert back to tensor\n",
    "        result = tf.numpy_function(\n",
    "            lambda x: apply_2d_fft(x.numpy() if hasattr(x, 'numpy') else x),\n",
    "            [inputs],\n",
    "            tf.float32\n",
    "        )\n",
    "        result.set_shape([inputs.shape[0], inputs.shape[1], inputs.shape[2], 2])\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Input: (batch, 32, 32, 1) -> Output: (batch, 32, 32, 2)\n",
    "        return (input_shape[0], input_shape[1], input_shape[2], 2)\n",
    "\n",
    "print(\"Fourier Transform layer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed66c2",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ffc4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_cnn_head_a\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"simple_cnn_head_a\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,994</span> (476.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,994\u001b[0m (476.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,994</span> (476.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,994\u001b[0m (476.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_simple_cnn_head_a():\n",
    "    \"\"\"Ultra simple CNN - proven architecture\"\"\"\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            # Input\n",
    "            layers.Input(shape=(32, 32, 1)),\n",
    "            # Conv block 1\n",
    "            layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "            layers.MaxPooling2D(2),\n",
    "            # Conv block 2\n",
    "            layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "            layers.MaxPooling2D(2),\n",
    "            # Conv block 3\n",
    "            layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "            layers.MaxPooling2D(2),\n",
    "            # Dense\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.5),\n",
    "            # was 10\n",
    "            layers.Dense(10, activation=\"softmax\"),\n",
    "        ],\n",
    "        name=\"simple_cnn_head_a\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_simple_cnn_head_a()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b97257",
   "metadata": {},
   "source": [
    "## Fourier Transformation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a94e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2400\n",
      "Validation samples: 600\n",
      "Target A classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Train/validation split stratified on Target A (10 classes)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED,\n",
    "    stratify=y[:, 0]  # Stratify on Target A\n",
    ")\n",
    "\n",
    "# Extract only Target A\n",
    "y_train_a = y_train[:, 0]\n",
    "y_val_a = y_val[:, 0]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Target A classes: {len(np.unique(y_train_a))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a983d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Compile model for single task\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf540fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.1058 - loss: 2.3021 - val_accuracy: 0.1300 - val_loss: 2.2823\n",
      "Epoch 2/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1392 - loss: 2.2762 - val_accuracy: 0.1217 - val_loss: 2.2568\n",
      "Epoch 3/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1492 - loss: 2.2552 - val_accuracy: 0.1733 - val_loss: 2.2155\n",
      "Epoch 4/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1838 - loss: 2.2142 - val_accuracy: 0.2283 - val_loss: 2.1416\n",
      "Epoch 5/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1825 - loss: 2.1693 - val_accuracy: 0.2367 - val_loss: 2.0835\n",
      "Epoch 6/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1954 - loss: 2.1286 - val_accuracy: 0.2517 - val_loss: 2.0159\n",
      "Epoch 7/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2304 - loss: 2.0730 - val_accuracy: 0.2817 - val_loss: 1.9512\n",
      "Epoch 8/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2375 - loss: 2.0569 - val_accuracy: 0.2917 - val_loss: 1.9586\n",
      "Epoch 9/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2475 - loss: 2.0156 - val_accuracy: 0.3117 - val_loss: 1.9545\n",
      "Epoch 10/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2596 - loss: 1.9916 - val_accuracy: 0.3167 - val_loss: 1.8962\n",
      "Epoch 11/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2708 - loss: 1.9414 - val_accuracy: 0.2883 - val_loss: 1.9246\n",
      "Epoch 12/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2738 - loss: 1.9385 - val_accuracy: 0.3250 - val_loss: 1.8672\n",
      "Epoch 13/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2679 - loss: 1.9325 - val_accuracy: 0.3317 - val_loss: 1.8718\n",
      "Epoch 14/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2979 - loss: 1.8946 - val_accuracy: 0.3183 - val_loss: 1.8314\n",
      "Epoch 15/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2862 - loss: 1.8852 - val_accuracy: 0.3167 - val_loss: 1.8389\n",
      "Epoch 16/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3013 - loss: 1.8749 - val_accuracy: 0.3083 - val_loss: 1.8495\n",
      "Epoch 17/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2937 - loss: 1.8594 - val_accuracy: 0.3183 - val_loss: 1.8403\n",
      "Epoch 18/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2979 - loss: 1.8513 - val_accuracy: 0.3183 - val_loss: 1.8447\n",
      "Epoch 19/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3129 - loss: 1.8112 - val_accuracy: 0.3217 - val_loss: 1.8172\n",
      "Epoch 20/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3267 - loss: 1.7938 - val_accuracy: 0.3233 - val_loss: 1.8350\n",
      "Epoch 21/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3275 - loss: 1.7643 - val_accuracy: 0.3267 - val_loss: 1.8454\n",
      "Epoch 22/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3242 - loss: 1.7706 - val_accuracy: 0.3050 - val_loss: 1.8336\n",
      "Epoch 23/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3367 - loss: 1.7417 - val_accuracy: 0.3117 - val_loss: 1.8380\n",
      "Epoch 24/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3529 - loss: 1.7145 - val_accuracy: 0.3167 - val_loss: 1.8373\n",
      "Epoch 25/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3421 - loss: 1.6917 - val_accuracy: 0.3150 - val_loss: 1.8524\n",
      "Epoch 26/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3617 - loss: 1.6647 - val_accuracy: 0.3150 - val_loss: 1.8521\n",
      "Epoch 27/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3725 - loss: 1.6391 - val_accuracy: 0.3200 - val_loss: 1.8544\n",
      "Epoch 28/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3846 - loss: 1.6299 - val_accuracy: 0.3317 - val_loss: 1.8621\n",
      "Epoch 29/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3817 - loss: 1.5966 - val_accuracy: 0.3250 - val_loss: 1.9136\n",
      "Epoch 30/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3883 - loss: 1.5717 - val_accuracy: 0.3283 - val_loss: 1.9489\n",
      "Epoch 31/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4062 - loss: 1.5272 - val_accuracy: 0.3050 - val_loss: 2.0127\n",
      "Epoch 32/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4187 - loss: 1.5217 - val_accuracy: 0.3200 - val_loss: 1.9751\n",
      "Epoch 33/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3971 - loss: 1.5093 - val_accuracy: 0.3133 - val_loss: 2.0061\n",
      "Epoch 34/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4317 - loss: 1.4544 - val_accuracy: 0.3250 - val_loss: 2.0196\n",
      "Epoch 35/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4479 - loss: 1.4303 - val_accuracy: 0.3133 - val_loss: 2.0130\n",
      "Epoch 36/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4579 - loss: 1.4124 - val_accuracy: 0.3317 - val_loss: 1.9877\n",
      "Epoch 37/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4525 - loss: 1.3814 - val_accuracy: 0.3183 - val_loss: 2.0974\n",
      "Epoch 38/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4758 - loss: 1.3386 - val_accuracy: 0.3067 - val_loss: 2.0889\n",
      "Epoch 39/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4779 - loss: 1.3283 - val_accuracy: 0.3233 - val_loss: 2.1118\n",
      "Epoch 40/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4850 - loss: 1.3162 - val_accuracy: 0.3233 - val_loss: 2.1447\n",
      "Epoch 41/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4867 - loss: 1.2890 - val_accuracy: 0.3150 - val_loss: 2.0397\n",
      "Epoch 42/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4950 - loss: 1.2680 - val_accuracy: 0.3067 - val_loss: 2.2808\n",
      "Epoch 43/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5183 - loss: 1.2163 - val_accuracy: 0.3217 - val_loss: 2.2166\n",
      "Epoch 44/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5125 - loss: 1.2255 - val_accuracy: 0.3050 - val_loss: 2.3461\n",
      "Epoch 45/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5267 - loss: 1.1522 - val_accuracy: 0.3000 - val_loss: 2.2325\n",
      "Epoch 46/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5446 - loss: 1.1375 - val_accuracy: 0.3083 - val_loss: 2.4343\n",
      "Epoch 47/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5392 - loss: 1.1368 - val_accuracy: 0.2833 - val_loss: 2.5582\n",
      "Epoch 48/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5571 - loss: 1.1008 - val_accuracy: 0.3017 - val_loss: 2.5452\n",
      "Epoch 49/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5504 - loss: 1.1236 - val_accuracy: 0.2917 - val_loss: 2.5385\n",
      "Epoch 50/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5638 - loss: 1.0815 - val_accuracy: 0.3183 - val_loss: 2.7766\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train model (Head A only)\n",
    "history = model.fit(\n",
    "    X_train, y_train_a,\n",
    "    validation_data=(X_val, y_val_a),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c901de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL VALIDATION RESULTS - HEAD A (10-class)\n",
      "============================================================\n",
      "Validation Loss: 2.7766\n",
      "Validation Accuracy: 0.3183 (31.83%)\n",
      "Random baseline: 0.1000 (10.00%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val_a, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL VALIDATION RESULTS - HEAD A (10-class)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_val, verbose=0)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(pred_classes == y_val_a)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Random baseline: {1/10:.4f} ({100/10:.2f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0959b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m confidence \u001b[38;5;241m=\u001b[39m pred_probs[\u001b[38;5;241m0\u001b[39m][pred_class]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Apply FFT to get magnitude and phase\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m fft_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_2d_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (1, 32, 32, 2)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m fft_magnitude \u001b[38;5;241m=\u001b[39m fft_output[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Magnitude\u001b[39;00m\n\u001b[0;32m     20\u001b[0m fft_phase \u001b[38;5;241m=\u001b[39m fft_output[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Phase\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mapply_2d_fft\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply simple 2D FFT to batch of images - returns magnitude and phase\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Input shape: (batch, 32, 32, 1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Remove channel dimension for FFT\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m images_squeezed \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch, 32, 32)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply 2D FFT using numpy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m fft_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfft2(images_squeezed)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1697\u001b[0m, in \u001b[0;36msqueeze\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m squeeze()\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one"
     ]
    }
   ],
   "source": [
    "# Visualize individual samples with Fourier Transform as heatmaps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure how many samples to display (from 0 to n)\n",
    "n = 10  # <-- Change this value to display more or fewer samples\n",
    "\n",
    "# Display n samples from validation set\n",
    "for i in range(n):\n",
    "    sample_image = X_val[i].squeeze()  # Shape: (32, 32)\n",
    "    true_class = y_val_a[i]\n",
    "    \n",
    "    # Predict class\n",
    "    pred_probs = model.predict(X_val[i:i+1], verbose=0)\n",
    "    pred_class = np.argmax(pred_probs)\n",
    "    confidence = pred_probs[0][pred_class]\n",
    "    \n",
    "    # Apply FFT to get magnitude and phase\n",
    "    fft_output = apply_2d_fft(X_val[i:i+1])  # Shape: (1, 32, 32, 2)\n",
    "    fft_magnitude = fft_output[0, :, :, 0]  # Magnitude\n",
    "    fft_phase = fft_output[0, :, :, 1]  # Phase\n",
    "    \n",
    "    # Create 3-panel visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Original image\n",
    "    im0 = axes[0].imshow(sample_image, cmap='gray', interpolation='nearest')\n",
    "    axes[0].set_title('Original Image', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_xlabel('X coordinate')\n",
    "    axes[0].set_ylabel('Y coordinate')\n",
    "    plt.colorbar(im0, ax=axes[0], label='Intensity')\n",
    "    \n",
    "    # FFT Magnitude\n",
    "    im1 = axes[1].imshow(fft_magnitude, cmap='hot', interpolation='nearest')\n",
    "    axes[1].set_title('FFT Magnitude (Log Scale)', fontsize=11, fontweight='bold')\n",
    "    axes[1].set_xlabel('Frequency X')\n",
    "    axes[1].set_ylabel('Frequency Y')\n",
    "    plt.colorbar(im1, ax=axes[1], label='Magnitude')\n",
    "    \n",
    "    # FFT Phase\n",
    "    im2 = axes[2].imshow(fft_phase, cmap='twilight', interpolation='nearest')\n",
    "    axes[2].set_title('FFT Phase', fontsize=11, fontweight='bold')\n",
    "    axes[2].set_xlabel('Frequency X')\n",
    "    axes[2].set_ylabel('Frequency Y')\n",
    "    plt.colorbar(im2, ax=axes[2], label='Phase')\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle(f'Sample {i} | True Class: {true_class} | Predicted: {pred_class} (confidence: {confidence:.2%})', \n",
    "                 fontsize=13, fontweight='bold', y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution in Validation Set:\")\n",
    "unique, counts = np.unique(y_val_a, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {cnt} samples ({cnt/len(y_val_a)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confusion matrix to see which classes are confused\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get confusion matrix\n",
    "cm = confusion_matrix(y_val_a, pred_classes)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title('Confusion Matrix - Target A (10 classes)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nPer-Class Performance:\")\n",
    "print(classification_report(y_val_a, pred_classes, digits=3))\n",
    "\n",
    "# Find most confused pairs\n",
    "print(\"\\nMost Confused Class Pairs:\")\n",
    "for i in range(10):\n",
    "    for j in range(i+1, 10):\n",
    "        if cm[i, j] + cm[j, i] > 10:  # Significant confusion\n",
    "            print(f\"  Classes {i} ↔ {j}: {cm[i,j]} + {cm[j,i]} = {cm[i,j] + cm[j,i]} confusions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6916ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0].axhline(y=0.1, color='r', linestyle='--', label='Random (10%)', alpha=0.5)\n",
    "axes[0].set_title('Head A: 10-Class Classification Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1].set_title('Loss', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training and validation plots displayed above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
